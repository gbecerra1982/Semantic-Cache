# üöÄ Cach√© Sem√°ntica con Azure AI Foundry

Una implementaci√≥n de cach√© sem√°ntica inteligente que utiliza Azure AI Foundry para optimizar las llamadas a GPT-4, reduciendo costos y mejorando el rendimiento hasta 20x mediante la detecci√≥n de consultas sem√°nticamente similares.

## üìã Tabla de Contenidos

- [Caracter√≠sticas](#-caracter√≠sticas)
- [Arquitectura](#-arquitectura)
- [Requisitos Previos](#-requisitos-previos)
- [Instalaci√≥n](#-instalaci√≥n)
- [Configuraci√≥n](#-configuraci√≥n)
- [Uso](#-uso)
- [Implementaci√≥n en API Management](#-implementaci√≥n-en-api-management)
- [Monitoreo y M√©tricas](#-monitoreo-y-m√©tricas)
- [Mejores Pr√°cticas](#-mejores-pr√°cticas)

## ‚ú® Caracter√≠sticas

- **üß† Detecci√≥n Sem√°ntica Inteligente**: Identifica consultas similares aunque est√©n escritas de forma diferente
- **‚ö° Mejora de Rendimiento 20x**: Respuestas en ~0.3s vs ~5s en llamadas directas
- **üí∞ Reducci√≥n de Costos**: Evita llamadas redundantes a GPT-4
- **üîÑ Persistencia**: La cach√© se guarda entre ejecuciones
- **üìä M√©tricas Detalladas**: Hit rate, tiempos de respuesta y an√°lisis de similitudes
- **üîå Integraci√≥n con Azure AI Foundry**: Compatible con los √∫ltimos modelos de OpenAI en Azure

## üèó Arquitectura

```mermaid
graph LR
    A[Cliente] --> B[API Management]
    B --> C{Cach√© Sem√°ntica}
    C -->|Cache Hit| D[Redis Cache]
    C -->|Cache Miss| E[Azure AI Foundry]
    E --> F[GPT-4.1]
    E --> G[text-embedding-3-large]
    C --> H[FAISS Index]
```

### Componentes Principales:

1. **Azure AI Foundry**: Plataforma integrada para acceder a modelos de OpenAI
2. **FAISS**: B√∫squeda vectorial eficiente para encontrar similitudes
3. **Redis Cache**: Almacenamiento de respuestas (opcional para producci√≥n)
4. **API Management**: Gesti√≥n de pol√≠ticas y throttling

## üì¶ Requisitos Previos

### Software
- Python 3.8+
- pip (gestor de paquetes de Python)

### Servicios de Azure
- Azure AI Foundry con deployments configurados:
  - GPT-4.1 (para generaci√≥n de respuestas)
  - text-embedding-3-large (para embeddings)
- Azure API Management (opcional para producci√≥n)
- Azure Redis Cache (opcional para escalabilidad)

## üõ† Instalaci√≥n

1. **Clonar o descargar el archivo `SemanticCache.py`**

2. **Instalar dependencias**:
```bash
pip install openai numpy faiss-cpu azure-ai-inference azure-core
```

Para GPU (opcional, mejor rendimiento):
```bash
pip install faiss-gpu
```

## ‚öô Configuraci√≥n

### Credenciales de Azure AI Foundry

El script solicitar√° las siguientes configuraciones al ejecutarse:

```
üîß CONFIGURACI√ìN DE AZURE AI FOUNDRY
============================================================
1. Azure OpenAI SDK con endpoint de OpenAI
2. Azure OpenAI SDK con endpoint de Foundry (RECOMENDADO)
3. Azure AI Foundry SDK (experimental)
```

**Valores predeterminados incluidos**:
- Endpoint: `https://foundry-proyecto1.openai.azure.com/`
- API Key: (se solicitar√° o usa la configurada)
- Deployments:
  - GPT: `gpt-4.1`
  - Embeddings: `text-embedding-3-large`

### Configuraci√≥n de Umbral de Similitud

En el archivo `SemanticCache.py`, puedes ajustar:

```python
SIMILARITY_THRESHOLD = 0.85  # Ajustar entre 0.7 - 0.95
```

- **0.70-0.80**: Captura m√°s variaciones (m√°s cache hits)
- **0.85-0.90**: Balance entre precisi√≥n y cobertura
- **0.90-0.95**: Solo consultas muy similares

## üöÄ Uso

### Ejecuci√≥n B√°sica

```bash
python SemanticCache.py
```

### Flujo de Ejecuci√≥n

1. **Configuraci√≥n Inicial**:
   - Selecciona opci√≥n 2 (Azure OpenAI SDK con Foundry)
   - Presiona Enter para usar valores predeterminados

2. **Pruebas Autom√°ticas**:
   - Ejecuta 11 consultas de prueba
   - Detecta similitudes sem√°nticas
   - Muestra estad√≠sticas en tiempo real

3. **Resultados**:
   ```
   üìà RESUMEN FINAL:
   - Total de consultas: 11
   - Cache hits: 3
   - Cache misses: 8
   - Hit rate final: 27.27%
   - Entradas en cach√©: 8
   ```

### Integraci√≥n en tu Aplicaci√≥n

```python
from SemanticCache import SemanticCache, create_client

# Configuraci√≥n
config = {
    'use_foundry': False,
    'endpoint': 'https://foundry-proyecto1.openai.azure.com/',
    'api_key': 'tu-api-key',
    'gpt_deployment': 'gpt-4.1',
    'embedding_deployment': 'text-embedding-3-large',
    'api_version': '2024-02-01'
}

# Inicializar
chat_client, embedding_client = create_client(config)
cache = SemanticCache(config=config)
cache.load()

# Usar
response = call_gpt_with_cache(prompt, chat_client, cache, config)
```

## üîß Implementaci√≥n en API Management

### üìù Gu√≠a Visual Paso a Paso para Configurar las Pol√≠ticas

#### 1. **Acceder a Azure Portal y API Management**

1. **Inicia sesi√≥n** en [Azure Portal](https://portal.azure.com)
   
2. **Buscar API Management**:
   - En la barra de b√∫squeda superior, escribe "API Management"
   - Click en "API Management services"
   - Selecciona tu instancia (ej: `apim0-m5gd7y67cu5b6`)

3. **Navegaci√≥n inicial**:
   ```
   Azure Portal Home
   ‚îî‚îÄ‚îÄ API Management services
       ‚îî‚îÄ‚îÄ apim0-m5gd7y67cu5b6 (tu instancia)
           ‚îú‚îÄ‚îÄ Overview
           ‚îú‚îÄ‚îÄ APIs  ‚Üê Click aqu√≠
           ‚îú‚îÄ‚îÄ Products
           ‚îî‚îÄ‚îÄ ...
   ```

#### 2. **Importar o Seleccionar la API de Azure OpenAI**

**Opci√≥n A: Si ya tienes la API importada**

1. En el men√∫ lateral izquierdo, click en **"APIs"**
2. Busca en la lista:
   - "Azure OpenAI Service API" o
   - "AI Foundry API" o
   - "Contoso Chat API"
3. **Click** en la API para seleccionarla

**Opci√≥n B: Si necesitas importar la API**

1. En la secci√≥n APIs, click en **"+ Add API"**
2. Selecciona **"OpenAPI"** (el tile con el logo de OpenAPI)
3. En el formulario que aparece:
   
   **From URL**:
   - **OpenAPI specification**: 
     ```
     https://raw.githubusercontent.com/Azure/azure-rest-api-specs/main/specification/cognitiveservices/data-plane/AzureOpenAI/inference/stable/2024-02-01/inference.json
     ```
   - **Display name**: Azure OpenAI Service API
   - **Name**: azure-openai-api
   - **API URL suffix**: openai
   - **Subscription required**: ‚úì (marcado)

4. Click **"Create"**

#### 3. **Configurar la Pol√≠tica Global (All Operations)**

1. **Dentro de tu API**, ver√°s tres secciones:
   ```
   Frontend    Processing    Backend
   ```

2. En la secci√≥n **"Processing"**, busca **"All operations"** y haz click
   
3. En **"Inbound processing"**, ver√°s un icono de c√≥digo **"</>"**
   - Click en **"</>"** (Policy code editor)

4. **Se abrir√° el editor de pol√≠ticas** con c√≥digo XML b√°sico:
   ```xml
   <policies>
       <inbound>
           <base />
       </inbound>
       <backend>
           <base />
       </backend>
       <outbound>
           <base />
       </outbound>
       <on-error>
           <base />
       </on-error>
   </policies>
   ```

5. **BORRA TODO** y **PEGA** el siguiente c√≥digo completo:

```xml
<policies>
    <inbound>
        <base />
        
        <!-- PASO 1: Rate Limiting por API Key -->
        <rate-limit-by-key calls="100" renewal-period="60" 
                           counter-key="@(context.Request.Headers.GetValueOrDefault("api-key","anonymous"))" />
        
        <!-- PASO 2: Throttling adicional por IP -->
        <rate-limit-by-key calls="20" renewal-period="1" 
                           counter-key="@(context.Request.IpAddress)" />
        
        <!-- PASO 3: Extraer informaci√≥n del request -->
        <set-variable name="requestBody" value="@(context.Request.Body.As<JObject>(preserveContent: true))" />
        <set-variable name="userPrompt" value="@{
            var body = (JObject)context.Variables["requestBody"];
            var messages = body["messages"] as JArray;
            return messages?.Last?["content"]?.ToString() ?? "";
        }" />
        
        <!-- PASO 4: Verificar cach√© simple primero -->
        <cache-lookup-value key="@($"response-{context.Variables["userPrompt"].ToString().GetHashCode()}")" 
                           variable-name="cachedResponse" />
        
        <choose>
            <when condition="@(context.Variables.ContainsKey("cachedResponse"))">
                <!-- Cache Hit! Devolver respuesta cacheada -->
                <set-variable name="cacheHit" value="true" />
                <return-response>
                    <set-status code="200" reason="OK" />
                    <set-header name="Content-Type" exists-action="override">
                        <value>application/json</value>
                    </set-header>
                    <set-header name="X-Cache-Status" exists-action="override">
                        <value>HIT</value>
                    </set-header>
                    <set-body>@((string)context.Variables["cachedResponse"])</set-body>
                </return-response>
            </when>
        </choose>
    </inbound>
    
    <backend>
        <base />
    </backend>
    
    <outbound>
        <base />
        
        <!-- PASO 5: Guardar respuesta nueva en cach√© -->
        <choose>
            <when condition="@(context.Response.StatusCode == 200 && !context.Variables.ContainsKey("cacheHit"))">
                <set-variable name="responseBody" value="@(context.Response.Body.As<string>(preserveContent: true))" />
                
                <cache-store-value 
                    key="@($"response-{context.Variables["userPrompt"].ToString().GetHashCode()}")" 
                    value="@((string)context.Variables["responseBody"])" 
                    duration="3600" />
                
                <set-header name="X-Cache-Status" exists-action="override">
                    <value>MISS</value>
                </set-header>
            </when>
        </choose>
    </outbound>
    
    <on-error>
        <base />
    </on-error>
</policies>
```

6. Click en **"Save"** (bot√≥n azul arriba)

#### 4. **Configurar Named Values (Variables Globales)**

Las Named Values son variables que puedes usar en todas tus pol√≠ticas:

1. **En el men√∫ lateral** de API Management, busca y click en **"Named values"**
   ```
   API Management
   ‚îú‚îÄ‚îÄ Overview
   ‚îú‚îÄ‚îÄ APIs
   ‚îú‚îÄ‚îÄ Products
   ‚îú‚îÄ‚îÄ Named values  ‚Üê Click aqu√≠
   ‚îî‚îÄ‚îÄ ...
   ```

2. Click en **"+ Add"** para crear cada valor:

   **Variable 1: API Key de Foundry**
   - **Name**: `foundry-api-key`
   - **Display name**: Foundry API Key
   - **Type**: Secret (seleccionar "Secret" del dropdown)
   - **Value**: `44E5Jtv6MfBOtx7565zFDoGXV8hTHeUrokBk7DdArzC69NAFC7ZxJQQJ99BFAC4f1cMXJ3w3AAAAACOGVYsT`
   - Click **"Save"**

   **Variable 2: Deployment de Embeddings**
   - **Name**: `embedding-deployment`
   - **Display name**: Embedding Deployment Name
   - **Type**: Plain
   - **Value**: `text-embedding-3-large`
   - Click **"Save"**

   **Variable 3: Deployment de GPT**
   - **Name**: `gpt-deployment`
   - **Display name**: GPT Deployment Name
   - **Type**: Plain
   - **Value**: `gpt-4.1`
   - Click **"Save"**

   **Variable 4: Umbral de Similitud**
   - **Name**: `similarity-threshold`
   - **Display name**: Similarity Threshold
   - **Type**: Plain
   - **Value**: `0.85`
   - Click **"Save"**

#### 5. **Configurar Subscriptions (Claves de API)**

Para que los clientes puedan acceder a tu API:

1. En el men√∫ lateral, click en **"Subscriptions"**
   ```
   API Management
   ‚îú‚îÄ‚îÄ Overview
   ‚îú‚îÄ‚îÄ APIs
   ‚îú‚îÄ‚îÄ Products
   ‚îú‚îÄ‚îÄ Subscriptions  ‚Üê Click aqu√≠
   ‚îî‚îÄ‚îÄ ...
   ```

2. Click en **"+ Add subscription"**:
   - **Name**: app1-subscription
   - **Display name**: App1 Subscription
   - **Scope**: API (selecciona tu Azure OpenAI API)
   - **Allow tracing**: ‚úì (para debugging)
   - Click **"Create"**

3. Una vez creada, click en los **"..."** y selecciona **"Show/hide keys"**
   - Copia la **Primary key**: Esta es la clave que usar√°n tus aplicaciones

#### 6. **Configurar Products (Opcional - Para diferentes tiers)**

Si quieres ofrecer diferentes niveles de servicio:

1. En el men√∫ lateral, click en **"Products"**
2. Click en **"+ Add"**:
   
   **Producto B√°sico**:
   - **Display name**: Basic Tier
   - **Id**: basic-tier
   - **Description**: 10 requests per minute
   - **Requires subscription**: ‚úì
   - **Requires approval**: ‚úó
   - **Subscription count limit**: 100
   - APIs: Selecciona tu Azure OpenAI API
   - Click **"Create"**

3. **Configurar l√≠mites del producto**:
   - Click en el producto creado
   - Ve a **"Policies"**
   - Agrega esta pol√≠tica:
   ```xml
   <policies>
       <inbound>
           <rate-limit calls="10" renewal-period="60" />
           <quota calls="1000" renewal-period="86400" />
       </inbound>
   </policies>
   ```

#### 7. **Testing de la Configuraci√≥n**

1. **Volver a APIs** ‚Üí Selecciona tu API ‚Üí Click en **"Test"** tab

2. **Selecciona una operaci√≥n**: 
   - Por ejemplo: "Creates a completion for the chat message"

3. **Configura los par√°metros de prueba**:
   
   **Headers**:
   - `api-key`: (tu API key de Foundry)
   - `Content-Type`: application/json

   **Request body**:
   ```json
   {
     "messages": [
       {
         "role": "system",
         "content": "You are a helpful assistant."
       },
       {
         "role": "user",
         "content": "What are Python best practices?"
       }
     ],
     "max_tokens": 100,
     "temperature": 0.7
   }
   ```

4. Click **"Send"**

5. **Verificar los resultados**:
   - Primera llamada: Header `X-Cache-Status: MISS`
   - Segunda llamada id√©ntica: Header `X-Cache-Status: HIT`
   - El tiempo de respuesta debe ser mucho menor en el HIT

#### 8. **Monitoreo en Tiempo Real**

1. En el men√∫ de API Management, click en **"Analytics"**
   ```
   API Management
   ‚îú‚îÄ‚îÄ Overview
   ‚îú‚îÄ‚îÄ APIs
   ‚îú‚îÄ‚îÄ Analytics  ‚Üê Click aqu√≠
   ‚îî‚îÄ‚îÄ ...
   ```

2. Aqu√≠ puedes ver:
   - Request count
   - Response time
   - Bandwidth
   - Errors

3. Para m√©tricas detalladas de cach√©, ve a **"Metrics"**:
   - Click en **"+ Add metric"**
   - Namespace: Microsoft.ApiManagement/service
   - Metric: Requests
   - Add filter: Response Code = 200
   - Add splitting: By Cache Status

### üîç Verificaci√≥n de la Implementaci√≥n

Para confirmar que todo funciona:

1. **Logs en tiempo real**:
   - Ve a **"Diagnostic settings"**
   - Habilita **"Send to Log Analytics"**
   - En Log Analytics, ejecuta:
   ```kusto
   ApiManagementGatewayLogs
   | where TimeGenerated > ago(1h)
   | where OperationName contains "completion"
   | project TimeGenerated, Cache_Status_s, ResponseTime, ResponseCode
   | order by TimeGenerated desc
   ```

2. **Application Insights** (si est√° conectado):
   - Ve a tu Application Insights
   - Click en **"Logs"**
   - Ejecuta:
   ```kusto
   requests
   | where timestamp > ago(1h)
   | where name contains "openai"
   | extend CacheStatus = tostring(customDimensions["Cache-Status"])
   | summarize count() by CacheStatus
   ```

### üö® Troubleshooting Com√∫n

**Error: "Policy expression failed"**
- Verifica que el JSON del request tenga el formato esperado
- Aseg√∫rate de que `messages` sea un array

**Error: "Named value not found"**
- Ve a Named values y verifica que existan todas las variables
- Los nombres son case-sensitive

**Cache no funciona**
- Verifica que el header `X-Cache-Status` est√© presente
- Revisa que la duraci√≥n del cach√© (3600 segundos) no haya expirado
- Confirma que los prompts sean exactamente iguales

```xml
<policies>
    <inbound>
        <base />
        
        <!-- Rate Limiting Escalonado -->
        <choose>
            <when condition="@(context.Request.Headers.GetValueOrDefault("Ocp-Apim-Subscription-Key","") == "premium-key")">
                <rate-limit-by-key calls="1000" renewal-period="60" 
                                   counter-key="@(context.Request.Headers.GetValueOrDefault("Ocp-Apim-Subscription-Key","anonymous"))" />
            </when>
            <when condition="@(context.Request.Headers.GetValueOrDefault("Ocp-Apim-Subscription-Key","") == "standard-key")">
                <rate-limit-by-key calls="100" renewal-period="60" 
                                   counter-key="@(context.Request.Headers.GetValueOrDefault("Ocp-Apim-Subscription-Key","anonymous"))" />
            </when>
            <otherwise>
                <rate-limit-by-key calls="10" renewal-period="60" 
                                   counter-key="@(context.Request.IpAddress)" />
            </otherwise>
        </choose>
        
        <!-- Extraer prompt -->
        <set-variable name="requestBody" value="@(context.Request.Body.As<JObject>(preserveContent: true))" />
        <set-variable name="userPrompt" value="@{
            var body = (JObject)context.Variables["requestBody"];
            var messages = body["messages"] as JArray;
            return messages?.Last?["content"]?.ToString() ?? "";
        }" />
        
        <!-- Generar embedding del prompt -->
        <send-request mode="new" response-variable-name="embeddingResponse" timeout="10" ignore-error="false">
            <set-url>@($"https://foundry-proyecto1.openai.azure.com/openai/deployments/{context.Variables["embedding-deployment"]}/embeddings?api-version=2024-02-01")</set-url>
            <set-method>POST</set-method>
            <set-header name="api-key" exists-action="override">
                <value>{{foundry-api-key}}</value>
            </set-header>
            <set-header name="Content-Type" exists-action="override">
                <value>application/json</value>
            </set-header>
            <set-body>@{
                return new JObject(
                    new JProperty("input", context.Variables["userPrompt"])
                ).ToString();
            }</set-body>
        </send-request>
        
        <!-- Extraer vector de embedding -->
        <set-variable name="promptEmbedding" value="@{
            var response = ((IResponse)context.Variables["embeddingResponse"]);
            if (response.StatusCode == 200) {
                var body = response.Body.As<JObject>();
                return body["data"][0]["embedding"].ToString();
            }
            return null;
        }" />
        
        <!-- Buscar en Redis similares (ejemplo simplificado) -->
        <send-request mode="new" response-variable-name="redisSearchResponse" timeout="5" ignore-error="true">
            <set-url>https://tu-function-app.azurewebsites.net/api/SemanticSearch</set-url>
            <set-method>POST</set-method>
            <set-header name="x-functions-key" exists-action="override">
                <value>{{function-key}}</value>
            </set-header>
            <set-body>@{
                return new JObject(
                    new JProperty("embedding", context.Variables["promptEmbedding"]),
                    new JProperty("threshold", 0.85),
                    new JProperty("topK", 1)
                ).ToString();
            }</set-body>
        </send-request>
        
        <!-- Verificar si hay match sem√°ntico -->
        <set-variable name="semanticMatch" value="@{
            var response = ((IResponse)context.Variables["redisSearchResponse"]);
            if (response != null && response.StatusCode == 200) {
                var body = response.Body.As<JObject>();
                var matches = body["matches"] as JArray;
                if (matches != null && matches.Count > 0) {
                    var bestMatch = matches[0];
                    if ((float)bestMatch["similarity"] > 0.85) {
                        return bestMatch["response"].ToString();
                    }
                }
            }
            return null;
        }" />
        
        <choose>
            <when condition="@(context.Variables["semanticMatch"] != null)">
                <!-- Semantic Cache Hit -->
                <return-response>
                    <set-status code="200" reason="OK" />
                    <set-header name="Content-Type" exists-action="override">
                        <value>application/json</value>
                    </set-header>
                    <set-header name="X-Cache-Status" exists-action="override">
                        <value>HIT-SEMANTIC</value>
                    </set-header>
                    <set-body>@((string)context.Variables["semanticMatch"])</set-body>
                </return-response>
            </when>
        </choose>
    </inbound>
    
    <backend>
        <base />
    </backend>
    
    <outbound>
        <base />
        
        <!-- Guardar respuesta nueva con embedding -->
        <choose>
            <when condition="@(context.Response.StatusCode == 200 && context.Variables["semanticMatch"] == null)">
                <send-one-way-request>
                    <set-url>https://tu-function-app.azurewebsites.net/api/StoreResponse</set-url>
                    <set-method>POST</set-method>
                    <set-header name="x-functions-key" exists-action="override">
                        <value>{{function-key}}</value>
                    </set-header>
                    <set-body>@{
                        return new JObject(
                            new JProperty("prompt", context.Variables["userPrompt"]),
                            new JProperty("embedding", context.Variables["promptEmbedding"]),
                            new JProperty("response", context.Response.Body.As<string>())
                        ).ToString();
                    }</set-body>
                </send-one-way-request>
            </when>
        </choose>
        
        <!-- Application Insights Custom Events -->
        <choose>
            <when condition="@(context.Variables.ContainsKey("semanticMatch"))">
                <log-to-eventhub logger-id="ai-logger">@{
                    return new JObject(
                        new JProperty("EventName", "SemanticCacheHit"),
                        new JProperty("Prompt", context.Variables["userPrompt"]),
                        new JProperty("ResponseTime", context.Elapsed.TotalMilliseconds)
                    ).ToString();
                }</log-to-eventhub>
            </when>
            <otherwise>
                <log-to-eventhub logger-id="ai-logger">@{
                    return new JObject(
                        new JProperty("EventName", "SemanticCacheMiss"),
                        new JProperty("Prompt", context.Variables["userPrompt"]),
                        new JProperty("ResponseTime", context.Elapsed.TotalMilliseconds)
                    ).ToString();
                }</log-to-eventhub>
            </otherwise>
        </choose>
    </outbound>
    
    <on-error>
        <base />
    </on-error>
</policies>
```

### üìä Configuraci√≥n de Rate Limiting Detallada

#### D√≥nde Configurar Rate Limiting

Rate limiting se puede configurar en tres niveles:

1. **Nivel Global (All APIs)**:
   - API Management ‚Üí **Policies** ‚Üí Click en **"Add policy"**
   
2. **Nivel de Producto**:
   - API Management ‚Üí **Products** ‚Üí Selecciona producto ‚Üí **Policies**
   
3. **Nivel de API/Operaci√≥n**:
   - API Management ‚Üí **APIs** ‚Üí Selecciona API ‚Üí **All operations** o espec√≠fica

#### Tipos de Rate Limiting con Ejemplos

1. **Por Subscription Key** (Recomendado para APIs comerciales):
```xml
<rate-limit-by-key calls="100" renewal-period="60" 
                   counter-key="@(context.Request.Headers.GetValueOrDefault("Ocp-Apim-Subscription-Key","anonymous"))" />
```

2. **Por IP Address** (Para APIs p√∫blicas):
```xml
<rate-limit-by-key calls="20" renewal-period="60" 
                   counter-key="@(context.Request.IpAddress)" />
```

3. **Por Usuario Autenticado (JWT)**:
```xml
<rate-limit-by-key calls="200" renewal-period="60" 
                   counter-key="@(context.Request.Headers.GetValueOrDefault("Authorization","anonymous").AsJwt()?.Subject)" />
```

4. **Rate Limiting Escalonado por Tipo de Suscripci√≥n**:

Primero, crear diferentes productos en API Management:

**a) Crear Producto Basic:**
- API Management ‚Üí **Products** ‚Üí **"+ Add"**
- Display name: **Basic Tier**
- Id: **basic-tier**
- APIs: Selecciona tu API
- **Create**

**b) En las pol√≠ticas del producto Basic:**
```xml
<policies>
    <inbound>
        <rate-limit calls="10" renewal-period="60" />
        <quota calls="1000" renewal-period="86400" />
    </inbound>
</policies>
```

**c) Crear Producto Premium:**
- Repetir proceso con:
- Display name: **Premium Tier**
- Id: **premium-tier**

**d) En las pol√≠ticas del producto Premium:**
```xml
<policies>
    <inbound>
        <rate-limit calls="1000" renewal-period="60" />
        <quota calls="100000" renewal-period="86400" />
    </inbound>
</policies>
```

5. **Rate Limiting Din√°mico basado en Headers**:
```xml
<choose>
    <when condition="@(context.Request.Headers.GetValueOrDefault("Client-Tier","") == "premium")">
        <rate-limit-by-key calls="1000" renewal-period="60" 
                           counter-key="@(context.Request.Headers.GetValueOrDefault("api-key","anonymous"))" />
    </when>
    <when condition="@(context.Request.Headers.GetValueOrDefault("Client-Tier","") == "standard")">
        <rate-limit-by-key calls="100" renewal-period="60" 
                           counter-key="@(context.Request.Headers.GetValueOrDefault("api-key","anonymous"))" />
    </when>
    <otherwise>
        <rate-limit-by-key calls="10" renewal-period="60" 
                           counter-key="@(context.Request.IpAddress)" />
    </otherwise>
</choose>
```

### üß™ Testing de Rate Limiting

1. **Usando Postman o curl**:
```bash
# Test b√°sico
for i in {1..15}; do
  curl -X POST https://apim0-m5gd7y67cu5b6.azure-api.net/openai/deployments/gpt-4.1/chat/completions \
    -H "api-key: YOUR_KEY" \
    -H "Content-Type: application/json" \
    -d '{"messages":[{"role":"user","content":"Hello"}]}'
  echo " - Request $i"
  sleep 1
done
```

2. **Verificar headers de respuesta**:
   - `X-RateLimit-Limit`: L√≠mite de llamadas
   - `X-RateLimit-Remaining`: Llamadas restantes
   - `X-RateLimit-Reset`: Cu√°ndo se resetea

3. **Respuesta cuando se excede el l√≠mite**:
```json
{
  "statusCode": 429,
  "message": "Rate limit is exceeded. Try again in 54 seconds."
}
```

## üìä Dashboard Personalizado para Monitoreo

### üéØ Creaci√≥n del Dashboard en Azure Portal - Gu√≠a Visual Completa

#### Paso 1: Crear un nuevo Dashboard

1. **En Azure Portal**, en la barra superior, busca el icono de **"Dashboard"** (parece una cuadr√≠cula)
   
2. Click en la **flecha hacia abajo** junto a "Dashboard" ‚Üí **"+ New dashboard"**

3. Selecciona **"Blank dashboard"**

4. **Nombra tu dashboard**:
   - Click en "My Dashboard" (t√≠tulo por defecto)
   - Escribe: **"Semantic Cache Performance Monitor"**
   - Click en **"Done customizing"**

#### Paso 2: Agregar Application Insights al Dashboard

Antes de agregar tiles, necesitas conectar Application Insights:

1. **Busca tu Application Insights**:
   - En la barra de b√∫squeda: escribe el nombre de tu App Insights
   - Click en el recurso

2. **Anclar m√©tricas b√°sicas**:
   - En Application Insights, ve a **"Overview"**
   - En cada gr√°fico, click en el **"üìå"** (pin icon)
   - Selecciona tu dashboard "Semantic Cache Performance Monitor"

#### Paso 3: Configurar los Tiles del Dashboard

### üìà 1. **Cache Hit Rate** (Gr√°fico de l√≠nea)

**Ubicaci√≥n**: Azure Portal ‚Üí Dashboard ‚Üí Edit mode

1. Click **"+ Add tile"** ‚Üí **"Metrics chart"**

2. En el panel de configuraci√≥n:
   - Click **"Select a resource"**
   - Resource type: **API Management services**
   - Subscription: Tu suscripci√≥n
   - Resource: **apim0-m5gd7y67cu5b6**
   - Click **"Apply"**

3. **Configurar la m√©trica**:
   - Metric Namespace: **Microsoft.ApiManagement/service**
   - Metric: **Requests**
   - Aggregation: **Count**
   
4. **Agregar filtros**:
   - Click **"Add filter"**
   - Property: **ResponseCode**
   - Operator: **=**
   - Values: **200**
   
5. **Agregar divisi√≥n**:
   - Click **"Apply splitting"**
   - Split by: **BackendResponseCode**
   
6. **Personalizar el gr√°fico**:
   - Chart type: **Line chart**
   - Title: **"Cache Hit Rate Over Time"**
   - Size: Arrastra para hacerlo m√°s grande

**Alternativa con Application Insights Query**:

1. Click **"+ Add tile"** ‚Üí **"Application Insights"**
2. Selecciona tu App Insights
3. Click **"Analytics query"**
4. Pega esta query:

```kusto
customEvents
| where timestamp > ago(24h)
| where name in ("CacheHit", "CacheMiss")
| summarize 
    Hits = countif(name == "CacheHit"),
    Misses = countif(name == "CacheMiss")
    by bin(timestamp, 5m)
| extend HitRate = round(100.0 * Hits / (Hits + Misses), 2)
| project timestamp, HitRate, TotalRequests = Hits + Misses
| render timechart with (ytitle="Hit Rate %", xtitle="Time")
```

5. Click **"Run query"** para preview
6. Click **"Done"**

### ‚è±Ô∏è 2. **Response Time Comparison** (Gr√°fico de barras)

1. **"+ Add tile"** ‚Üí **"Application Insights"** ‚Üí **"Analytics query"**

2. **Query**:
```kusto
requests
| where timestamp > ago(24h)
| where name contains "openai"
| extend CacheStatus = iff(responseCode == 200 and duration < 1000, "Cache Hit", "Cache Miss")
| summarize 
    AvgDuration = avg(duration),
    P95Duration = percentile(duration, 95),
    Count = count()
    by CacheStatus
| project 
    CacheStatus,
    ['Avg Response Time (ms)'] = round(AvgDuration, 0),
    ['P95 Response Time (ms)'] = round(P95Duration, 0),
    ['Request Count'] = Count
| render columnchart with (
    kind=grouped,
    title="Response Time: Cache Hit vs Miss",
    xtitle="Cache Status", 
    ytitle="Time (ms)"
)
```

### üí∞ 3. **Cost Savings Calculator** (KPI Tiles)

Para mostrar KPIs, necesitas crear Azure Functions que calculen estos valores:

**Opci√≥n A: KPI Est√°tico (Markdown)**

1. **"+ Add tile"** ‚Üí **"Markdown"**
2. Contenido:
```markdown
## üí∞ Ahorro de Hoy

### $127.45
**Tokens ahorrados**: 4,248,333  
**Llamadas evitadas**: 847  
**Hit Rate**: 31.2%
```

**Opci√≥n B: KPI Din√°mico con Logic App**

1. Crear una **Logic App** que:
   - Se ejecute cada 5 minutos
   - Consulte Application Insights
   - Calcule los ahorros
   - Actualice un Storage Table

2. En el dashboard, usar **"Metrics chart"** con el Storage Table

### üìä 4. **Top Queries Cached** (Tabla)

1. **"+ Add tile"** ‚Üí **"Application Insights"** ‚Üí **"Logs"**

2. **Query**:
```kusto
customEvents
| where timestamp > ago(24h)
| where name == "CacheHit"
| extend Prompt = substring(tostring(customDimensions["Prompt"]), 0, 50)
| summarize HitCount = count() by Prompt
| top 10 by HitCount desc
| project 
    ['Query'] = Prompt,
    ['Cache Hits'] = HitCount,
    ['% of Total'] = round(100.0 * HitCount / toscalar(
        customEvents 
        | where timestamp > ago(24h) 
        | where name == "CacheHit" 
        | count()
    ), 1)
| render table
```

3. **Configurar visualizaci√≥n**:
   - Title: **"Top 10 Cached Queries"**
   - Size: Medium/Large

### üå°Ô∏è 5. **System Health Metrics**

**Para API Management**:

1. **"+ Add tile"** ‚Üí **"Metrics chart"**
2. Resource: Tu API Management
3. Agregar m√©tricas m√∫ltiples:
   - Click **"Add metric"** para cada una:
   
   **M√©trica 1**: Capacity
   - Metric: **Capacity**
   - Aggregation: **Avg**
   - Color: Azul
   
   **M√©trica 2**: Requests
   - Metric: **Requests**
   - Aggregation: **Count**
   - Color: Verde

**Para Redis Cache**:

1. **"+ Add tile"** ‚Üí **"Metrics chart"**
2. Resource: **meli-testing01** (tu Redis)
3. M√©tricas:
   - **Cache Hits** (Sum)
   - **Cache Misses** (Sum)
   - **Used Memory** (Avg)
   - **Connected Clients** (Avg)

### üö¶ 6. **Real-time Status** (Live Metrics)

1. Abre tu **Application Insights**
2. En el men√∫, click **"Live metrics"**
3. En la parte superior derecha, click **"üìå Pin to dashboard"**
4. Selecciona tu dashboard

### üìà 7. **Trend Analysis** (An√°lisis de 7 d√≠as)

1. **"+ Add tile"** ‚Üí **"Application Insights"** ‚Üí **"Metrics"**
2. Configuraci√≥n:
   - Metric: **Custom Events**
   - Time range: **Last 7 days**
   - Granularity: **1 hour**
   - Chart type: **Area chart**

### üé® 8. **Cache Efficiency Heatmap**

1. **"+ Add tile"** ‚Üí **"Workbooks"** ‚Üí **"Empty"**
2. Click **"+ Add"** ‚Üí **"Add query"**
3. Query:
```kusto
customEvents
| where timestamp > ago(7d)
| where name in ("CacheHit", "CacheMiss")
| extend Hour = hourofday(timestamp)
| extend DayOfWeek = dayofweek(timestamp)
| summarize 
    HitRate = round(100.0 * countif(name == "CacheHit") / count(), 0)
    by Hour, DayOfWeek
| project Hour, DayOfWeek, HitRate
| render table with (
    kind=heatmap,
    title="Cache Hit Rate by Hour and Day"
)
```

### üîî 9. **Configurar Alertas**

**Desde el dashboard**:

1. Click en **"..."** en cualquier tile de m√©trica
2. Selecciona **"New alert rule"**

**Alerta 1: Low Cache Hit Rate**
- Resource: API Management
- Condition: 
  ```
  Custom log search
  Query: customEvents | where name in ("CacheHit", "CacheMiss") | summarize HitRate = ...
  Threshold: < 20
  Frequency: 5 minutes
  Period: 15 minutes
  ```
- Action: Email al equipo

**Alerta 2: High Response Time**
- Signal: Average Response Time
- Threshold: > 5000 ms
- Action: Webhook para auto-scaling

### üì± 10. **Mobile Dashboard**

1. En tu dashboard, click **"Share"** ‚Üí **"Mobile app"**
2. Descarga la app **"Azure mobile"**
3. Configura widgets para:
   - Hit Rate (n√∫mero grande)
   - √öltimas 6 horas (gr√°fico)
   - Alertas activas

### üéØ Organizaci√≥n del Dashboard

**Layout recomendado** (4 columnas):

```
[Cache Hit Rate - Large]  [Cost Savings - KPIs]
[Response Times - Med]    [System Health - Med]
[Top Queries - Large spanning 2 columns]
[7-Day Trends - Full width]
[Heatmap - Med]          [Alerts - Med]
```

### üíæ Guardar y Compartir

1. Click **"Save"** en la parte superior
2. Para compartir:
   - Click **"Share"**
   - Opci√≥n 1: **"Publish to the dashboards gallery"**
   - Opci√≥n 2: **"Generate link"** (para compartir externamente)

### üîß Automatizaci√≥n con ARM Template

Para replicar el dashboard en otros environments:

1. En el dashboard, click **"Download"**
2. Esto descarga un archivo JSON (ARM template)
3. Modifica los resource IDs
4. Deploy con:
```bash
az deployment group create \
  --resource-group myResourceGroup \
  --template-file dashboard.json
```

## üéØ Mejores Pr√°cticas

### 1. **Gesti√≥n de Cach√©**

```python
# Limpiar entradas antiguas
def cleanup_old_entries(cache, days=7):
    cutoff_date = datetime.now() - timedelta(days=days)
    # Implementar l√≥gica de limpieza
```

### 2. **Manejo de Errores**

```python
try:
    response = call_gpt_with_cache(prompt, client, cache, config)
except Exception as e:
    logger.error(f"Error en cach√© sem√°ntica: {e}")
    # Fallback a llamada directa
    response = direct_gpt_call(prompt, client)
```

### 3. **Seguridad**

- Nunca hardcodear API keys
- Usar Azure Key Vault para credenciales
- Implementar autenticaci√≥n en API Management

### 4. **Optimizaci√≥n**

- Pre-calcular embeddings para FAQs comunes
- Usar batch processing para m√∫ltiples consultas
- Implementar warming de cach√© en horarios de baja demanda

## üîç Troubleshooting

### Error: "AssertionError" en FAISS
- **Causa**: Dimensiones de embedding incorrectas
- **Soluci√≥n**: El c√≥digo detecta autom√°ticamente las dimensiones

### Error: "Unauthorized" 
- **Causa**: API key o endpoint incorrecto
- **Soluci√≥n**: Verificar credenciales en Azure AI Foundry

### Cache hits bajos
- **Causa**: Umbral muy alto
- **Soluci√≥n**: Reducir `SIMILARITY_THRESHOLD` a 0.75-0.80

### Error en API Management
- **Causa**: Pol√≠tica mal configurada
- **Soluci√≥n**: Verificar sintaxis XML y Named Values

### Redis connection timeout
- **Causa**: Firewall o configuraci√≥n de red
- **Soluci√≥n**: Verificar reglas de firewall y connection string

## üìà Resultados Esperados

Con una implementaci√≥n correcta, deber√≠as ver:

| M√©trica | Sin Cach√© | Con Cach√© | Mejora |
|---------|-----------|-----------|---------|
| Tiempo de Respuesta | 3-5 segundos | 0.2-0.5 segundos | 85-95% |
| Costo por Request | $0.03-0.05 | $0.001-0.005 | 90-95% |
| Throughput | 20 req/min | 200+ req/min | 10x |
| Latencia P99 | 8 segundos | 1 segundo | 87.5% |

### ROI Estimado

Para una aplicaci√≥n con 10,000 requests diarios:
- **Sin cach√©**: 10,000 √ó $0.04 = $400/d√≠a
- **Con cach√©** (30% hit rate): 7,000 √ó $0.04 + 3,000 √ó $0.005 = $295/d√≠a
- **Ahorro**: $105/d√≠a = $3,150/mes

## ü§ù Contribuciones

Para mejorar esta implementaci√≥n:
1. Implementar expiraci√≥n inteligente de cach√©
2. Agregar soporte para m√∫ltiples idiomas
3. Integrar con Azure Cosmos DB para persistencia distribuida
4. Crear SDK para diferentes lenguajes
5. Implementar cach√© jer√°rquico (L1: memoria, L2: Redis, L3: Cosmos)

## üìö Referencias

- [Azure AI Foundry Documentation](https://docs.microsoft.com/azure/ai-services/)
- [FAISS Documentation](https://github.com/facebookresearch/faiss)
- [Azure API Management Policies](https://docs.microsoft.com/azure/api-management/api-management-policies)
- [Application Insights KQL Reference](https://docs.microsoft.com/azure/data-explorer/kusto/query/)

## üìÑ Licencia

Este proyecto es de c√≥digo abierto y est√° disponible bajo la licencia MIT.