# ğŸš€ CachÃ© SemÃ¡ntico Optimizado para Azure OpenAI

ImplementaciÃ³n de cachÃ© semÃ¡ntico inteligente que reduce costos hasta un 90% y mejora el rendimiento hasta 20x mediante Azure API Management y Azure AI Foundry.

## ğŸ“‹ Tabla de Contenidos

- [Arquitectura del Sistema](#-arquitectura-del-sistema)
- [CaracterÃ­sticas Principales](#-caracterÃ­sticas-principales)
- [ImplementaciÃ³n desde Azure AI Foundry](#-implementaciÃ³n-desde-azure-ai-foundry)
- [ConfiguraciÃ³n de PolÃ­ticas](#-configuraciÃ³n-de-polÃ­ticas)
- [Scripts de Prueba y ValidaciÃ³n](#-scripts-de-prueba-y-validaciÃ³n)
- [Monitoreo y OptimizaciÃ³n](#-monitoreo-y-optimizaciÃ³n)
- [Mejores PrÃ¡cticas](#-mejores-prÃ¡cticas)

## ğŸ— Arquitectura del Sistema

```mermaid
graph TB
    subgraph "Cliente"
        A[AplicaciÃ³n/Usuario]
        B[SDK OpenAI/HTTP Client]
    end
    
    subgraph "Azure API Management"
        C[API Gateway]
        D[PolÃ­tica de CachÃ© SemÃ¡ntico]
        E{Router por OperaciÃ³n}
        F[PolÃ­tica Embeddings<br/>Threshold: 0.95]
        G[PolÃ­tica Completions<br/>Threshold: 0.10]
    end
    
    subgraph "CachÃ© Layer"
        H[(CachÃ© Interno APIM)]
        I[BÃºsqueda SemÃ¡ntica]
        J[Almacenamiento con TTL]
    end
    
    subgraph "Azure AI Foundry"
        K[AI Foundry Gateway]
        L[Deployment Manager]
        M[text-embedding-3-large]
        N[GPT-4]
    end
    
    subgraph "MÃ©tricas"
        O[Application Insights]
        P[Log Analytics]
        Q[Dashboards]
    end
    
    A --> B
    B --> C
    C --> D
    D --> E
    E -->|Embeddings| F
    E -->|Chat/Completions| G
    
    F --> I
    G --> I
    
    I -->|Cache Hit| H
    I -->|Cache Miss| K
    
    H -->|Return Cached| A
    
    K --> L
    L --> M
    L --> N
    
    M -->|Store Result| J
    N -->|Store Result| J
    J --> H
    
    D --> O
    O --> P
    P --> Q
    
    style C fill:#0078D4,stroke:#fff,stroke-width:2px
    style D fill:#FF6B6B,stroke:#fff,stroke-width:2px
    style H fill:#51CF66,stroke:#fff,stroke-width:2px
    style K fill:#FFA94D,stroke:#fff,stroke-width:2px
    style M fill:#845EF7,stroke:#fff,stroke-width:2px
    style N fill:#845EF7,stroke:#fff,stroke-width:2px
```

### Flujo de Datos:

1. **Cliente** envÃ­a request a API Management
2. **PolÃ­tica de CachÃ©** analiza el tipo de operaciÃ³n
3. **BÃºsqueda SemÃ¡ntica** verifica si existe respuesta similar
4. **Cache Hit**: Retorna respuesta inmediata (<200ms)
5. **Cache Miss**: Forward a Azure AI Foundry
6. **Almacenamiento**: Guarda respuesta con TTL optimizado

## âœ¨ CaracterÃ­sticas Principales

### ğŸ¯ Optimizaciones por Tipo de OperaciÃ³n

| OperaciÃ³n | Score Threshold | TTL | Particionamiento | Beneficio |
|-----------|----------------|-----|------------------|-----------|
| **Embeddings** | 0.95 | 30 dÃ­as | modelo, tipo, dimensiones, usuario | 95% reducciÃ³n en latencia |
| **Completions** | 0.10 | 2 horas | modelo, temperatura, tokens, usuario | 85% reducciÃ³n en costos |

### ğŸ’¡ Ventajas Clave

- **ReducciÃ³n de Costos**: Evita llamadas redundantes a modelos costosos
- **Mejora de Latencia**: Respuestas instantÃ¡neas desde cachÃ©
- **Escalabilidad**: Maneja picos de trÃ¡fico sin impactar el backend
- **Inteligencia**: Detecta consultas semÃ¡nticamente similares

## ğŸ”§ ImplementaciÃ³n desde Azure AI Foundry

### ğŸ“ Paso 1: Preparar Azure AI Foundry

**Â¿QuÃ© hace?**: Configura tu proyecto en AI Foundry con los modelos necesarios.

1. **Accede a Azure AI Foundry Studio**
   - Ve a [https://ai.azure.com](https://ai.azure.com)
   - Inicia sesiÃ³n con tu cuenta Azure

2. **Crea o selecciona un proyecto**
   ```
   AI Foundry Studio
   â””â”€â”€ All resources
       â””â”€â”€ + New project
           â”œâ”€â”€ Project name: "semantic-cache-project"
           â”œâ”€â”€ Hub: Selecciona o crea uno nuevo
           â””â”€â”€ Create
   ```

3. **Despliega los modelos necesarios**
   - En el menÃº lateral: **Deployments** â†’ **+ Deploy model**
   - Modelo 1: `gpt-4` (nombre: "gpt-4")
   - Modelo 2: `text-embedding-3-large` (nombre: "text-embedding-3-large")

### ğŸ“ Paso 2: Integrar con API Management

**Â¿QuÃ© hace?**: Conecta AI Foundry con API Management para aplicar las polÃ­ticas de cachÃ©.

SegÃºn la [documentaciÃ³n oficial de Microsoft](https://learn.microsoft.com/en-us/azure/api-management/azure-ai-foundry-api), sigue estos pasos:

1. **En Azure AI Foundry Studio**:
   ```
   Tu Proyecto
   â””â”€â”€ Management (menÃº lateral)
       â””â”€â”€ API access
           â””â”€â”€ Deploy to API Management
   ```

2. **Configura el despliegue**:
   - **API Management instance**: Selecciona tu instancia existente o crea una nueva
   - **API name**: `Azure AI Foundry API`
   - **API URL suffix**: `ai-foundry`
   - **Subscription required**: âœ“ Marcado
   - **Products**: Selecciona los productos aplicables

3. **Opciones de importaciÃ³n**:
   - âœ“ Import all Azure OpenAI endpoints
   - âœ“ Configure managed identity
   - âœ“ Add CORS policy

4. **Click "Deploy"**

**Beneficios de este mÃ©todo**:
- âœ… Importa automÃ¡ticamente todas las operaciones
- âœ… Configura la autenticaciÃ³n correctamente
- âœ… Agrega transformaciones necesarias
- âœ… Mantiene la compatibilidad con OpenAI SDK

### ğŸ“ Paso 3: Verificar la ImportaciÃ³n

**Â¿QuÃ© hace?**: Confirma que todas las operaciones se importaron correctamente.

1. **En Azure Portal**, navega a tu API Management:
   ```
   Azure Portal
   â””â”€â”€ API Management services
       â””â”€â”€ tu-instancia-apim
           â””â”€â”€ APIs
               â””â”€â”€ Azure AI Foundry API
   ```

2. **Verifica las operaciones**:
   DeberÃ­as ver:
   - `POST /deployments/{deployment-id}/chat/completions`
   - `POST /deployments/{deployment-id}/completions`
   - `POST /deployments/{deployment-id}/embeddings`
   - Otras operaciones de OpenAI

### ğŸ“ Paso 4: Aplicar PolÃ­tica para Embeddings

**Â¿QuÃ© hace?**: Configura cachÃ© semÃ¡ntico optimizado para operaciones de embedding con alta precisiÃ³n.

1. **Selecciona la operaciÃ³n de embeddings**:
   ```
   Azure AI Foundry API
   â””â”€â”€ All operations
       â””â”€â”€ CreateEmbeddings
           â””â”€â”€ Design view
   ```

2. **En "Inbound processing"**, click en `</>` (Policy code editor)

3. **Reemplaza con la polÃ­tica optimizada**:
   ```xml
   <policies>
       <inbound>
           <base />
           <!-- La polÃ­tica completa estÃ¡ en apim-policy-embeddings-only-v2.xml -->
       </inbound>
       <backend>
           <base />
       </backend>
       <outbound>
           <base />
           <!-- Almacena con TTL de 30 dÃ­as para embeddings -->
       </outbound>
       <on-error>
           <base />
       </on-error>
   </policies>
   ```

4. **Click "Save"**

**CaracterÃ­sticas de esta polÃ­tica**:
- **Score threshold: 0.95** - Solo cachea matches exactos
- **TTL: 30 dÃ­as** - Los embeddings son determinÃ­sticos
- **Particionamiento**: Por input_type, dimensions, user
- **Headers informativos**: X-Cache-Status, X-Cache-TTL-Days

### ğŸ“ Paso 5: Aplicar PolÃ­tica para Completions

**Â¿QuÃ© hace?**: Configura cachÃ© semÃ¡ntico flexible para chat y completions.

1. **Selecciona la operaciÃ³n de chat**:
   ```
   Azure AI Foundry API
   â””â”€â”€ All operations
       â””â”€â”€ CreateChatCompletion
           â””â”€â”€ Design view
   ```

2. **Aplica la polÃ­tica** desde `apim-policy-completions-only-v2.xml`

**CaracterÃ­sticas de esta polÃ­tica**:
- **Score threshold: 0.10** - Permite variaciones en consultas
- **TTL: 2 horas fijo** - Balance entre frescura y eficiencia
- **Particionamiento**: Por temperatura, max_tokens, user
- **Headers de optimizaciÃ³n**: Recomendaciones de TTL por temperatura

### ğŸ“ Paso 6: Configurar Backend y Seguridad

**Â¿QuÃ© hace?**: Asegura la conexiÃ³n entre API Management y AI Foundry.

1. **En Settings de la API**:
   ```
   Web service URL: https://tu-proyecto.openai.azure.com/openai
   ```

2. **Configurar Managed Identity**:
   - API Management â†’ Managed identities â†’ System assigned â†’ Status: On
   - Copia el Object ID

3. **En AI Foundry**, asigna permisos:
   - Project â†’ Access control (IAM)
   - Add role assignment â†’ Cognitive Services User
   - Assign to: Managed identity â†’ Select your APIM

### ğŸ“ Paso 7: Crear Subscription Keys

**Â¿QuÃ© hace?**: Genera claves de acceso para tus aplicaciones.

1. **En API Management â†’ Subscriptions**:
   ```
   + Add subscription
   â”œâ”€â”€ Name: production-app
   â”œâ”€â”€ Display name: Production Application
   â”œâ”€â”€ Scope: Azure AI Foundry API
   â””â”€â”€ Create
   ```

2. **ObtÃ©n las claves**:
   - Click en "..." â†’ Show/hide keys
   - Copia la Primary key

## ğŸ§ª Scripts de Prueba y ValidaciÃ³n

### ğŸ”¬ Test 1: ValidaciÃ³n de CachÃ© de Embeddings

**Archivo**: `test-embedding-cache.py`

**Â¿QuÃ© prueba?**
1. **Exactitud del threshold (0.95)**:
   - Verifica que solo consultas idÃ©nticas generan HIT
   - Valida que consultas similares generan MISS

2. **Particionamiento correcto**:
   - Diferentes `input_type` (query/document/passage)
   - Diferentes dimensiones (1536/3072)
   - Diferentes usuarios

3. **Batch processing**:
   - Arrays de inputs
   - ValidaciÃ³n de hash para batches

**Beneficios**:
- âœ… Confirma configuraciÃ³n correcta del threshold alto
- âœ… Valida el particionamiento para evitar colisiones
- âœ… Asegura persistencia de 30 dÃ­as

**EjecuciÃ³n**:
```bash
python test-embedding-cache.py

# Salida esperada:
â–¶ Test 2/10: Consulta idÃ©ntica - Debe ser HIT
Resultado:
  â””â”€ Cache Status: HIT
  â””â”€ Cache Score: 1.0
  â””â”€ TTL (dÃ­as): 30
  â””â”€ Tiempo de respuesta: 0.021s
  â””â”€ ValidaciÃ³n: âœ“ (Esperado: HIT)
```

### ğŸ”¬ Test 2: ValidaciÃ³n de CachÃ© de Completions

**Archivo**: `test-completions-cache.py`

**Â¿QuÃ© prueba?**
1. **Flexibilidad del threshold (0.10)**:
   - Consultas similares deben generar HIT
   - "What are Python best practices?" â‰ˆ "What are the Python best practices?"

2. **Grupos de temperatura**:
   - DeterminÃ­stica (0.0-0.2): Mayor reuso
   - Baja (0.2-0.5): Reuso moderado
   - Media (0.5-0.8): Reuso limitado
   - Alta (0.8+): MÃ­nimo reuso

3. **ParÃ¡metros avanzados**:
   - frequency_penalty y presence_penalty
   - Conversaciones multi-turno
   - Funciones/herramientas

**Beneficios**:
- âœ… Maximiza hit rate con threshold bajo
- âœ… Valida agrupaciÃ³n inteligente por temperatura
- âœ… Asegura compatibilidad con features avanzadas

**EjecuciÃ³n**:
```bash
python test-completions-cache.py

# MÃ©tricas generadas:
ğŸ“Š EstadÃ­sticas Generales:
  â””â”€ Hit Rate: 41.7%
  â””â”€ Mejora de velocidad: 15.2x

ğŸ’° EstimaciÃ³n de Ahorros:
  â””â”€ Ahorro mensual proyectado: $567.30
```

### ğŸ”¬ InterpretaciÃ³n de Resultados

**Headers de respuesta clave**:

```http
# Para Embeddings
X-Semantic-Cache-Status: HIT
X-Cache-TTL-Days: 30
X-Batch-Size: 5
X-Cache-Optimization-Tip: "Document embeddings cached for 30 days"

# Para Completions  
X-Semantic-Cache-Status: MISS
X-Recommended-TTL-Hours: 12
X-Temperature-Group: deterministic
X-Cache-Optimization-Tip: "Low temperature - consider longer TTL"
```

## ğŸ“Š Monitoreo y OptimizaciÃ³n

### Dashboard Recomendado

1. **Crear dashboard en Azure Portal**:
   ```
   Portal â†’ Dashboard â†’ + New dashboard
   â””â”€â”€ Semantic Cache Monitor
       â”œâ”€â”€ Hit Rate Chart (Line)
       â”œâ”€â”€ Response Time Comparison (Bar)
       â”œâ”€â”€ Cost Savings (KPI)
       â””â”€â”€ Top Cached Queries (Table)
   ```

2. **Queries de Application Insights**:
   ```kusto
   // Hit Rate por Hora
   customMetrics
   | where name == "CacheHitRate"
   | summarize avg(value) by bin(timestamp, 1h)
   | render timechart
   ```

### Alertas CrÃ­ticas

1. **Hit Rate Bajo**:
   - CondiciÃ³n: Hit Rate < 20%
   - AcciÃ³n: Revisar threshold y particionamiento

2. **Latencia Alta**:
   - CondiciÃ³n: P95 > 5 segundos
   - AcciÃ³n: Verificar backend y cachÃ©

## ğŸ¯ Mejores PrÃ¡cticas

### Para Embeddings

```python
# Normalizar texto para maximizar hits
text = text.lower().strip()
text = ' '.join(text.split())  # Normalizar espacios

# Especificar input_type
request = {
    "input": text,
    "input_type": "document",  # Mejora particionamiento
    "dimensions": 3072
}
```

### Para Completions

```python
# Para consultas frecuentes (FAQs)
request = {
    "messages": [...],
    "temperature": 0.1,  # Baja para consistencia
    "seed": 42,         # Reproducibilidad
    "max_tokens": 150   # Limitar variabilidad
}
```

### Monitoreo de Costos

| MÃ©trica | Sin CachÃ© | Con CachÃ© | Ahorro |
|---------|-----------|-----------|---------|
| Embeddings/dÃ­a | 10,000 Ã— $0.0004 = $4 | 6,000 Ã— $0.0004 = $2.40 | $1.60 (40%) |
| Completions/dÃ­a | 1,000 Ã— $0.03 = $30 | 700 Ã— $0.03 = $21 | $9 (30%) |
| **Total Mensual** | **$1,020** | **$702** | **$318** |

## ğŸš€ PrÃ³ximos Pasos

1. **Implementar Redis Cache** para escalabilidad horizontal
2. **Agregar compresiÃ³n** para respuestas grandes
3. **Crear SDK cliente** con retry automÃ¡tico
4. **Implementar warming** de cachÃ© para consultas comunes
5. **Agregar versionado** de respuestas cacheadas

## ğŸ“š Referencias

- [Azure AI Foundry + API Management](https://learn.microsoft.com/en-us/azure/api-management/azure-ai-foundry-api)
- [Semantic Cache Policies](https://learn.microsoft.com/azure/api-management/azure-openai-semantic-cache-lookup-policy)
- [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/)