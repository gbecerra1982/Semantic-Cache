# ğŸš€ CachÃ© SemÃ¡ntico Optimizado para Azure OpenAI

ImplementaciÃ³n de cachÃ© semÃ¡ntico inteligente que reduce costos hasta un 90% y mejora el rendimiento hasta 20x mediante Azure API Management y Azure AI Foundry.

## ğŸ“‹ Tabla de Contenidos

- [Arquitectura del Sistema](#-arquitectura-del-sistema)
- [CaracterÃ­sticas Principales](#-caracterÃ­sticas-principales)
- [ImplementaciÃ³n desde Azure AI Foundry](#-implementaciÃ³n-desde-azure-ai-foundry)
- [ConfiguraciÃ³n de PolÃ­ticas](#-configuraciÃ³n-de-polÃ­ticas)
- [Scripts de Prueba y ValidaciÃ³n](#-scripts-de-prueba-y-validaciÃ³n)
- [Monitoreo y OptimizaciÃ³n](#-monitoreo-y-optimizaciÃ³n)
- [Mejores PrÃ¡cticas](#-mejores-prÃ¡cticas)

## ğŸ— Arquitectura del Sistema

```mermaid
graph TB
    subgraph "Cliente"
        A[AplicaciÃ³n/Usuario]
        B[SDK OpenAI/HTTP Client]
    end
    
    subgraph "Azure API Management"
        C[API Gateway]
        D[PolÃ­tica de CachÃ© SemÃ¡ntico]
        E{Router por OperaciÃ³n}
        F[PolÃ­tica Embeddings<br/>Threshold: 0.95]
        G[PolÃ­tica Completions<br/>Threshold: 0.10]
    end
    
    subgraph "CachÃ© Layer"
        H[(CachÃ© Interno APIM)]
        I[BÃºsqueda SemÃ¡ntica]
        J[Almacenamiento con TTL]
        R[(Azure Cache for Redis)]
    end
    
    subgraph "Azure AI Foundry"
        K[AI Foundry Gateway]
        L[Deployment Manager]
        M[text-embedding-3-large]
        N[GPT-4.1]
    end
    
    subgraph "MÃ©tricas"
        O[Application Insights]
        P[Log Analytics]
        Q[Dashboards]
    end
    
    A --> B
    B --> C
    C --> D
    D --> E
    E -->|Embeddings| F
    E -->|Chat/Completions| G
    
    F --> I
    G --> I
    
    I -->|Cache Hit| H
    I -->|Cache Miss| K
    
    H -->|Redis Lookup| R
    R -->|Return Cached| A
    
    K --> L
    L --> M
    L --> N
    
    M -->|Store Result| J
    N -->|Store Result| J
    J --> H
    H -->|Persist| R
    
    D --> O
    O --> P
    P --> Q
    
    style C fill:#0078D4,stroke:#fff,stroke-width:2px
    style D fill:#FF6B6B,stroke:#fff,stroke-width:2px
    style H fill:#51CF66,stroke:#000,stroke-width:2px,color:#000
    style R fill:#DC382D,stroke:#fff,stroke-width:2px
    style K fill:#FFA94D,stroke:#fff,stroke-width:2px
    style M fill:#845EF7,stroke:#fff,stroke-width:2px
    style N fill:#845EF7,stroke:#fff,stroke-width:2px
```

### Flujo de Datos:

1. **Cliente** envÃ­a request a API Management
2. **PolÃ­tica de CachÃ©** analiza el tipo de operaciÃ³n
3. **BÃºsqueda SemÃ¡ntica** verifica si existe respuesta similar
4. **Redis Lookup**: Consulta en Azure Cache for Redis (meli-testing01)
5. **Cache Hit**: Retorna respuesta desde Redis (<50ms)
6. **Cache Miss**: Forward a Azure AI Foundry
7. **Almacenamiento**: Guarda respuesta en cachÃ© interno y persiste en Redis
8. **TTL Management**: Redis gestiona expiraciÃ³n automÃ¡tica

## âœ¨ CaracterÃ­sticas Principales

### ğŸ¯ Optimizaciones por Tipo de OperaciÃ³n

| OperaciÃ³n | Score Threshold | TTL | Particionamiento | Beneficio |
|-----------|----------------|-----|------------------|-----------|
| **Embeddings** | 0.95 | 30 dÃ­as | modelo, tipo, dimensiones, usuario | 95% reducciÃ³n en latencia |
| **Chat Completions** | 0.10 | 2 horas | modelo, temperatura, tokens, usuario | 85% reducciÃ³n en costos |

### ğŸ’¡ Ventajas Clave

- **ReducciÃ³n de Costos**: Evita llamadas redundantes a modelos costosos
- **Mejora de Latencia**: Respuestas instantÃ¡neas desde cachÃ©
- **Escalabilidad**: Maneja picos de trÃ¡fico sin impactar el backend
- **Inteligencia**: Detecta consultas semÃ¡nticamente similares

## ğŸ”§ ImplementaciÃ³n desde Azure AI Foundry

### ğŸ“ Paso 1: Preparar Azure AI Foundry

**Â¿QuÃ© hace?**: Configura tu proyecto en AI Foundry con los modelos necesarios.

1. **Accede a Azure AI Foundry Studio**
   - Ve a [https://ai.azure.com](https://ai.azure.com)
   - Inicia sesiÃ³n con tu cuenta Azure

2. **Crea o selecciona un proyecto**
   ```
   AI Foundry Studio
   â””â”€â”€ All resources
       â””â”€â”€ + New project
           â”œâ”€â”€ Project name: "semantic-cache-project"
           â”œâ”€â”€ Hub: Selecciona o crea uno nuevo
           â””â”€â”€ Create
   ```

3. **Despliega los modelos necesarios**
   - En el menÃº lateral: **Deployments** â†’ **+ Deploy model**
   - Modelo 1: `gpt-4` (nombre: "gpt-4.1")
   - Modelo 2: `text-embedding-3-large` (nombre: "text-embedding-3-large")

### ğŸ“ Paso 2: Importar API de AI Foundry en API Management

**Â¿QuÃ© hace?**: Importa la definiciÃ³n de API de Azure AI Foundry para poder aplicar las polÃ­ticas de cachÃ©.

SegÃºn la [documentaciÃ³n oficial de Microsoft](https://learn.microsoft.com/en-us/azure/api-management/azure-ai-foundry-api), sigue estos pasos:

1. **En Azure Portal, navega a tu API Management**:
   ```
   Azure Portal
   â””â”€â”€ API Management services
       â””â”€â”€ tu-instancia-apim
           â””â”€â”€ APIs (menÃº lateral)
               â””â”€â”€ + Add API
   ```

2. **Selecciona "Create from Azure resource"**:
   - En las opciones que aparecen, busca y selecciona:
   - **Azure AI Foundry**
   - DescripciÃ³n: "Connect API Management services to Azure AI Foundry"

3. **Configura la conexiÃ³n con AI Foundry**:
   - **Subscription**: Tu suscripciÃ³n de Azure
   - **Resource**: Selecciona tu proyecto de AI Foundry
   - **Display name**: `Azure AI Foundry API`
   - **Name**: `azure-ai-foundry-api`
   - **API URL suffix**: `ai-foundry`
   - **Base URL**: Se autocompletarÃ¡ con tu endpoint de AI Foundry
   - **Products**: Starter, Unlimited (o los que tengas configurados)
   - **Gateways**: Managed

4. **ConfiguraciÃ³n de autenticaciÃ³n**:
   - **Import method**: âœ“ Use managed identity
   - **User assigned managed identity**: Selecciona si tienes una configurada
   - **Add all AI Foundry operations**: âœ“ Marcado

5. **Click "Create"**

**QuÃ© hace automÃ¡ticamente**:
- âœ… Importa todas las operaciones de OpenAI (chat, completions, embeddings)
- âœ… Configura la autenticaciÃ³n con managed identity
- âœ… Establece el backend correcto de AI Foundry
- âœ… Mantiene compatibilidad con SDKs de OpenAI

### ğŸ“ Paso 3: Verificar la ImportaciÃ³n

**Â¿QuÃ© hace?**: Confirma que todas las operaciones se importaron correctamente.

1. **En Azure Portal**, navega a tu API Management:
   ```
   Azure Portal
   â””â”€â”€ API Management services
       â””â”€â”€ tu-instancia-apim
           â””â”€â”€ APIs
               â””â”€â”€ Azure AI Foundry API
   ```

2. **Verifica las operaciones**:
   DeberÃ­as ver:
   - `POST /deployments/{deployment-id}/chat/completions`
   - `POST /deployments/{deployment-id}/completions`
   - `POST /deployments/{deployment-id}/embeddings`
   - Otras operaciones de OpenAI

### ğŸ“ Paso 4: Aplicar PolÃ­tica para Embeddings

**Â¿QuÃ© hace?**: Configura cachÃ© semÃ¡ntico optimizado para operaciones de embedding con alta precisiÃ³n.

1. **Navega a la operaciÃ³n de embeddings**:
   ```
   APIs
   â””â”€â”€ Azure AI Foundry API
       â””â”€â”€ All operations (vista de lista)
           â””â”€â”€ Busca: "Creates embeddings" o "/deployments/{deployment-id}/embeddings"
           â””â”€â”€ Click en la operaciÃ³n
   ```

2. **Entra al editor de polÃ­ticas**:
   - En la vista de diseÃ±o de la operaciÃ³n
   - En la secciÃ³n **"Inbound processing"**
   - Click en el icono **`</>`** (Policy code editor)

3. **Borra todo el contenido existente y pega la polÃ­tica completa**:
   
   **IMPORTANTE**: Copia TODO el contenido del archivo `apim-policy-embeddings-only-v2.xml` que incluye:

   ```xml
   <policies>
       <inbound>
           <base />
           
           <!-- Configurar el backend para embeddings -->
           <set-backend-service id="apim-generated-policy" backend-id="aoai-meli-openai-endpoint" />
           
           <!-- Extraer y validar el request body -->
           <set-variable name="requestBody" value="@(context.Request.Body.As<JObject>(preserveContent: true))" />
           
           <!-- Extraer parÃ¡metros especÃ­ficos de embeddings -->
           <set-variable name="input-type" value="@{
               var body = (JObject)context.Variables[&quot;requestBody&quot;];
               return body[&quot;input_type&quot;]?.ToString() ?? &quot;query&quot;;
           }" />
           
           <!-- ... resto de la polÃ­tica ... -->
           
           <!-- CachÃ© SemÃ¡ntico Optimizado para Embeddings -->
           <azure-openai-semantic-cache-lookup 
               score-threshold="0.95"
               embeddings-backend-id="text-embedding-3-large" 
               embeddings-backend-auth="system-assigned">
               <!-- ... configuraciÃ³n de vary-by ... -->
           </azure-openai-semantic-cache-lookup>
       </inbound>
       
       <backend>
           <base />
       </backend>
       
       <outbound>
           <base />
           <!-- TTL de 30 dÃ­as para embeddings -->
           <choose>
               <when condition="@(context.Response.StatusCode == 200)">
                   <azure-openai-semantic-cache-store duration="2592000" />
               </when>
           </choose>
           <!-- ... headers de monitoreo ... -->
       </outbound>
       
       <on-error>
           <base />
           <!-- ... manejo de errores ... -->
       </on-error>
   </policies>
   ```

4. **Actualiza el backend-id si es necesario**:
   - Busca: `backend-id="aoai-meli-openai-endpoint"`
   - Reemplaza con tu backend ID real

5. **Click "Save"**

**CaracterÃ­sticas clave de esta polÃ­tica**:
- **Score threshold: 0.95** - Solo cachea coincidencias exactas
- **TTL: 30 dÃ­as (2592000 segundos)** - Embeddings son determinÃ­sticos
- **Particionamiento avanzado**: 
  - Por tipo de input (query/document/passage)
  - Por dimensiones (1536/3072)
  - Por usuario
  - Hash exacto del input
- **Headers de monitoreo**:
  - `X-Semantic-Cache-Status`: HIT/MISS
  - `X-Cache-TTL-Days`: 30
  - `X-Embedding-Type`: query/document/passage
  - `X-Batch-Size`: Para operaciones batch

### ğŸ“ Paso 5: Aplicar PolÃ­tica para Chat Completions

**Â¿QuÃ© hace?**: Configura cachÃ© semÃ¡ntico flexible para operaciones de chat con threshold bajo.

1. **Navega a la operaciÃ³n de chat completions**:
   ```
   APIs
   â””â”€â”€ Azure AI Foundry API
       â””â”€â”€ All operations
           â””â”€â”€ Busca: "Creates a chat completion" o "/deployments/{deployment-id}/chat/completions"
           â””â”€â”€ Click en la operaciÃ³n
   ```

2. **Entra al editor de polÃ­ticas**:
   - Click en **`</>`** en "Inbound processing"

3. **Borra todo y pega el contenido completo de `apim-policy-completions-only-v2.xml`**:

   ```xml
   <policies>
       <inbound>
           <base />
           
           <!-- Configurar el backend para completions -->
           <set-backend-service id="apim-generated-policy" backend-id="aoai-meli-openai-endpoint" />
           
           <!-- Extraer parÃ¡metros del request -->
           <set-variable name="requestBody" value="@(context.Request.Body.As<JObject>(preserveContent: true))" />
           
           <set-variable name="temperature" value="@{
               var body = (JObject)context.Variables[&quot;requestBody&quot;];
               return body[&quot;temperature&quot;]?.Value<float>() ?? 0.7f;
           }" />
           
           <!-- ... resto de variables ... -->
           
           <!-- CachÃ© SemÃ¡ntico para Completions -->
           <azure-openai-semantic-cache-lookup 
               score-threshold="0.10"
               embeddings-backend-id="text-embedding-3-large" 
               embeddings-backend-auth="system-assigned" 
               max-message-count="20">
               <!-- ... configuraciÃ³n de vary-by ... -->
           </azure-openai-semantic-cache-lookup>
       </inbound>
       
       <backend>
           <base />
       </backend>
       
       <outbound>
           <base />
           <!-- TTL fijo de 2 horas -->
           <choose>
               <when condition="@(context.Response.StatusCode == 200)">
                   <azure-openai-semantic-cache-store duration="7200" />
               </when>
           </choose>
           <!-- ... headers de monitoreo ... -->
       </outbound>
       
       <on-error>
           <base />
       </on-error>
   </policies>
   ```

4. **Actualiza el backend-id**

5. **Click "Save"**

**CaracterÃ­sticas clave de esta polÃ­tica**:
- **Score threshold: 0.10** - Permite consultas similares
- **TTL: 2 horas (7200 segundos)** - Balance frescura/eficiencia
- **Particionamiento inteligente**:
  - Por grupo de temperatura (deterministic/low/medium/high)
  - Por rango de max_tokens
  - Por usuario
  - Por system message
  - Por funciones/herramientas
- **Headers informativos**:
  - `X-Temperature-Group`: ClasificaciÃ³n de temperatura
  - `X-Recommended-TTL-Hours`: TTL sugerido por temperatura
  - `X-Cache-Optimization-Tip`: Consejos de optimizaciÃ³n

### ğŸ“ Paso 5.1: Aplicar PolÃ­tica para Completions (Opcional)

Si tambiÃ©n usas el endpoint de completions (no chat):

1. **Navega a**: `/deployments/{deployment-id}/completions`
2. **Aplica la misma polÃ­tica** de completions
3. La polÃ­tica detectarÃ¡ automÃ¡ticamente el tipo de operaciÃ³n

### ğŸ“ Paso 6: Configurar Backend y Seguridad

**Â¿QuÃ© hace?**: Asegura la conexiÃ³n entre API Management y AI Foundry.

1. **En Settings de la API**:
   ```
   Web service URL: https://tu-proyecto.openai.azure.com/openai
   ```

2. **Configurar Managed Identity**:
   - API Management â†’ Managed identities â†’ System assigned â†’ Status: On
   - Copia el Object ID

3. **En AI Foundry**, asigna permisos:
   - Project â†’ Access control (IAM)
   - Add role assignment â†’ Cognitive Services User
   - Assign to: Managed identity â†’ Select your APIM

### ğŸ“ Paso 7: Crear Subscription Keys

**Â¿QuÃ© hace?**: Genera claves de acceso para tus aplicaciones.

1. **En API Management â†’ Subscriptions**:
   ```
   + Add subscription
   â”œâ”€â”€ Name: production-app
   â”œâ”€â”€ Display name: Production Application
   â”œâ”€â”€ Scope: Azure AI Foundry API
   â””â”€â”€ Create
   ```

2. **ObtÃ©n las claves**:
   - Click en "..." â†’ Show/hide keys
   - Copia la Primary key

## ğŸ§ª Scripts de Prueba y ValidaciÃ³n

### ğŸ”¬ Test 1: ValidaciÃ³n de CachÃ© de Embeddings

**Archivo**: `test-embedding-cache.py`

**Â¿QuÃ© prueba?**
1. **Exactitud del threshold (0.95)**:
   - Verifica que solo consultas idÃ©nticas generan HIT
   - Valida que consultas similares generan MISS

2. **Particionamiento correcto**:
   - Diferentes `input_type` (query/document/passage)
   - Diferentes dimensiones (1536/3072)
   - Diferentes usuarios

3. **Batch processing**:
   - Arrays de inputs
   - ValidaciÃ³n de hash para batches

**Beneficios**:
- âœ… Confirma configuraciÃ³n correcta del threshold alto
- âœ… Valida el particionamiento para evitar colisiones
- âœ… Asegura persistencia de 30 dÃ­as

**EjecuciÃ³n**:
```bash
python test-embedding-cache.py

# Salida esperada:
â–¶ Test 2/10: Consulta idÃ©ntica - Debe ser HIT
Resultado:
  â””â”€ Cache Status: HIT
  â””â”€ Cache Score: 1.0
  â””â”€ TTL (dÃ­as): 30
  â””â”€ Tiempo de respuesta: 0.021s
  â””â”€ ValidaciÃ³n: âœ“ (Esperado: HIT)
```

### ğŸ”¬ Test 2: ValidaciÃ³n de CachÃ© de Completions

**Archivo**: `test-completions-cache.py`

**Â¿QuÃ© prueba?**
1. **Flexibilidad del threshold (0.10)**:
   - Consultas similares deben generar HIT
   - "What are Python best practices?" â‰ˆ "What are the Python best practices?"

2. **Grupos de temperatura**:
   - DeterminÃ­stica (0.0-0.2): Mayor reuso
   - Baja (0.2-0.5): Reuso moderado
   - Media (0.5-0.8): Reuso limitado
   - Alta (0.8+): MÃ­nimo reuso

3. **ParÃ¡metros avanzados**:
   - frequency_penalty y presence_penalty
   - Conversaciones multi-turno
   - Funciones/herramientas

**Beneficios**:
- âœ… Maximiza hit rate con threshold bajo
- âœ… Valida agrupaciÃ³n inteligente por temperatura
- âœ… Asegura compatibilidad con features avanzadas

**EjecuciÃ³n**:
```bash
python test-completions-cache.py

# MÃ©tricas generadas:
ğŸ“Š EstadÃ­sticas Generales:
  â””â”€ Hit Rate: 41.7%
  â””â”€ Mejora de velocidad: 15.2x

ğŸ’° EstimaciÃ³n de Ahorros:
  â””â”€ Ahorro mensual proyectado: $567.30
```

### ğŸ”¬ InterpretaciÃ³n de Resultados

**Headers de respuesta clave**:

```http
# Para Embeddings
X-Semantic-Cache-Status: HIT
X-Cache-TTL-Days: 30
X-Batch-Size: 5
X-Cache-Optimization-Tip: "Document embeddings cached for 30 days"

# Para Completions  
X-Semantic-Cache-Status: MISS
X-Recommended-TTL-Hours: 12
X-Temperature-Group: deterministic
X-Cache-Optimization-Tip: "Low temperature - consider longer TTL"
```

## ğŸ“Š Monitoreo y OptimizaciÃ³n

### Dashboard Recomendado

1. **Crear dashboard en Azure Portal**:
   ```
   Portal â†’ Dashboard â†’ + New dashboard
   â””â”€â”€ Semantic Cache Monitor
       â”œâ”€â”€ Hit Rate Chart (Line)
       â”œâ”€â”€ Response Time Comparison (Bar)
       â”œâ”€â”€ Cost Savings (KPI)
       â””â”€â”€ Top Cached Queries (Table)
   ```

2. **Queries de Application Insights**:
   ```kusto
   // Hit Rate por Hora
   customMetrics
   | where name == "CacheHitRate"
   | summarize avg(value) by bin(timestamp, 1h)
   | render timechart
   ```

### Alertas CrÃ­ticas

1. **Hit Rate Bajo**:
   - CondiciÃ³n: Hit Rate < 20%
   - AcciÃ³n: Revisar threshold y particionamiento

2. **Latencia Alta**:
   - CondiciÃ³n: P95 > 5 segundos
   - AcciÃ³n: Verificar backend y cachÃ©

## ğŸ¯ Mejores PrÃ¡cticas

### Para Embeddings

```python
# Normalizar texto para maximizar hits
text = text.lower().strip()
text = ' '.join(text.split())  # Normalizar espacios

# Especificar input_type
request = {
    "input": text,
    "input_type": "document",  # Mejora particionamiento
    "dimensions": 3072
}
```

### Para Completions

```python
# Para consultas frecuentes (FAQs)
request = {
    "messages": [...],
    "temperature": 0.1,  # Baja para consistencia
    "seed": 42,         # Reproducibilidad
    "max_tokens": 150   # Limitar variabilidad
}
```

### Monitoreo de Costos

| MÃ©trica | Sin CachÃ© | Con CachÃ© | Ahorro |
|---------|-----------|-----------|---------|
| Embeddings/dÃ­a | 10,000 Ã— $0.0004 = $4 | 6,000 Ã— $0.0004 = $2.40 | $1.60 (40%) |
| Completions/dÃ­a | 1,000 Ã— $0.03 = $30 | 700 Ã— $0.03 = $21 | $9 (30%) |
| **Total Mensual** | **$1,020** | **$702** | **$318** |

## ğŸš€ PrÃ³ximos Pasos

1. **Implementar Redis Cache** para escalabilidad horizontal
2. **Agregar compresiÃ³n** para respuestas grandes
3. **Crear SDK cliente** con retry automÃ¡tico
4. **Implementar warming** de cachÃ© para consultas comunes
5. **Agregar versionado** de respuestas cacheadas

## ğŸ“š Referencias

- [Azure AI Foundry + API Management](https://learn.microsoft.com/en-us/azure/api-management/azure-ai-foundry-api)
- [Semantic Cache Policies](https://learn.microsoft.com/azure/api-management/azure-openai-semantic-cache-lookup-policy)
- [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/)